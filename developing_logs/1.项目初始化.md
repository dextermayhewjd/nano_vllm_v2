#

## 1) 初始化项目骨架（uv init）

初始化项目骨架（uv init）

在你想放 repo 的目录里：

```bash
mkdir nano_vllm
cd nano_vllm


#  生成 src 布局的“打包式项目”（会创建 pyproject.toml / README / src/nano_vllm/__init__.py 等）
uv init --package nano_vllm
```

uv init --package 会帮你直接搭好 src/ 结构（更像工程，而不是随手脚本）。

验收：

```bash
ls

# 你会看到：pyproject.toml .python-version README.md src/ uv.lock（第一次 run/sync 后会出现）等
```

## 2) 配置 PyTorch 的 CUDA wheel 来源（关键：别装到 cpu-only）

PyTorch 的 CUDA 轮子通常要走 download.pytorch.org 的 index（比如 cu130 / cu128 / cu126）。PyTorch 官方“Previous Versions”页面给了明确的 --index-url 安装命令（同一版本对应不同 CUDA）。

uv 支持在 pyproject.toml 里配置额外 index，并且可以把某些包固定从某个 index 装（这对 torch 特别重要）。

### 2.1 编辑 pyproject.toml：加上下面这段

把它追加到文件末尾（或合适位置）：

```
[tool.uv.sources]
torch = { index = "pytorch-cu130" }
torchvision = { index = "pytorch-cu130" }
torchaudio = { index = "pytorch-cu130" }

[[tool.uv.index]]
name = "pytorch-cu130"
url = "https://download.pytorch.org/whl/cu130"
explicit = true
```

如果你机器/驱动对 cu130 不合适，把 cu130 换成 cu128 或 cu126 即可（PyTorch 官方页都有）。

## 3) 用 uv add 安装依赖（含 torch / transformers / safetensors）

uv 的 uv add 会把依赖写进 pyproject.toml，并更新锁文件与环境。

### 3.1 安装 PyTorch（按你选的版本）

我这里直接用 PyTorch 官方页面里示例的 v2.9.1 + cu130（你也可以选 2.9.0/2.8.0 等）。

```bash
uv add 'torch==2.9.1' 'torchvision==0.24.1' 'torchaudio==2.9.1'
```

### 3.2 安装 HF 推理所需依赖

```bash
uv add transformers safetensors huggingface-hub
```

（有些模型 tokenizer 可能会需要额外依赖，后面缺什么再补；先别过度加。）

### 3.3 开发依赖（pytest）

```bash
uv add --dev pytest
```

## 4) 立刻验收：torch CUDA 是否可用

```bash
uv run python -c "import torch; print('cuda?', torch.cuda.is_available()); print('torch', torch.__version__); print('cuda_ver', torch.version.cuda);"
```

uv run 会保证锁文件与环境一致，跑命令前会自动同步环境